# Study and Implementation of Bottleneck Transformers for Visual Recognition

## Overview
This repository explores and implements concepts from the research paper "Bottleneck Transformers for Visual Recognition" by Aravind Srinivas, Tsung-Yi Lin, and others from Google Research. The repository contains both a detailed presentation of the study and Jupyter notebooks with practical implementations.

## Paper Details
- **Title**: Bottleneck Transformers for Visual Recognition
- **Authors**: Aravind Srinivas, Tsung-Yi Lin, et al.
- **Link**: [Read the paper](https://arxiv.org/pdf/2101.11605)
- **Published**: 2021

## Repository Structure
- `Bottleneck Transformers.pdf`: A presentation that outlines the key concepts and findings from the paper.
- `Bottleneck_Transformer.ipynb`: Jupyter notebook with the implementation of the bottleneck transformer model as described in the paper.

## Key Concepts
The research introduces a novel hybrid architecture that combines the robustness of CNNs with the efficiency of self-attention mechanisms from transformers to address the challenges in visual recognition tasks such as object detection and image classification.

## Installation
Please run our notebook `Bottleneck_Transformer.ipynb` top to bottom

## Team Members
Will Qi, Tin Do, Tarunyaa Tarunyaa Sivakumar
